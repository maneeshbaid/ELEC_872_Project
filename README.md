# Refining Recognition Accuracy for Wearable Sensor Data in Human Activity Recognition
Maneesh Baid </br>
Department of Electrical and Computer Engineering</br>
Queen’s University</br>
</br>
</br>
This git repository contains the code for implementing three new methods: CNN-LSTM with Multi-Head Attention, CNN-TCN, CNN-TCN with Multi-Head Attention for MHEALTH and the WISDM dataset. We utilized the code by Singh et al. [1], available on GitHub [2], as a baseline for our code. Chatgpt [3] was utilized to get the syntax and fix bugs.
</br>
Datasets are available in the dataset/LOTO folder, and the code for these new methods is under the codes/model_proposed folder.
## Setup
1) Make sure python 3 is installed.
2) Run this command - pip install -r requirements.txt to install the necessary packages.

## References
[1] S. P. Singh, M. K. Sharma, A. Lay-Ekuakille, D. Gangwar, and S. Gupta, “Deep ConvLSTM with self-attention for human activity decoding using wearable sensors,” IEEE Sensors J., vol. 21, no. 6, pp. 8575–8582, Mar. 2021.</br>
[2] S. P. Singh, M. K. Sharma, A. Lay-Ekuakille, D. Gangwar and S. Gupta, "Deep ConvLSTM with self-attention for human activity decoding using wearable sensors," in IEEE Sensors Journal, doi: 10.1109/JSEN.2020.3045135 - GitHub repository, [Online]. Available: https://github.com/isukrit/encodingHumanActivity </br>
[3] OpenAI. (2024). ChatGPT [Large language model]. https://chatgpt.com
</br>
